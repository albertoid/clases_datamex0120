{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística   (SoftMax)\n",
    "\n",
    "\n",
    "**Con datos del MNIST, clasificación de números escritos a mano. (1vsALL)**\n",
    "\n",
    "\n",
    "![](imgs/sig_plot.png)\n",
    "\n",
    "\n",
    "# Versión Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando...\n",
      "\n",
      "Modelo SoftMax (MLR) : Numeros\n"
     ]
    }
   ],
   "source": [
    "import time                                                 # para tiempo\n",
    "inicio=time.time()                                          # momento inicial\n",
    "print ('Comenzando...\\n')\n",
    "print ('Modelo SoftMax (MLR) : Numeros')    \n",
    "import pandas as pd                                         # dataframe\n",
    "import numpy as np                                          # numerical python, algebra lineal\n",
    "import matplotlib.pyplot as plt                             # plots, graficos\n",
    "import seaborn as sns                                       # plots\n",
    "from sklearn.metrics import confusion_matrix                # metricas, matriz de confusion\n",
    "from scipy.optimize import minimize                         # minimizar, opt\n",
    "from numba import jit                                       # compilacion y paralelizacion, velocidad\n",
    "import warnings                                             # avisos\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # elimino un warning por valores NaN en logaritmos o /0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se crean las funciones de las ecuaciones principales del modelo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/sigmoide.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,a):                                 # funcion logistica, sigmoide, funcion del modelo, con z=X*alfa, el producto escalar\n",
    "    return 1.0/(1.0+np.exp(-np.dot(X,a)))   # Boltzmann con pivote, alfa[i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/coste.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
    "    return -(np.sum(np.log(f(X,a)))+np.dot((y-1).T,(np.dot(X,a))))/y.size+lambda_reg/(2.0*y.size)*np.dot(a[1:],a[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/grad_coste.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
    "    return (np.dot(X.T,(f(X,a)-y)))/y.size+lambda_reg/(2.0*y.size)*np.concatenate(([0], a[1:])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para normalizar los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def normalizador(X):                # normalizador de X\n",
    "    X_media=X.mean(axis=0)          # media de X\n",
    "    X_std=X.std(axis=0)             # desviacion estandar de X\n",
    "    X_std[X_std==0]=1.0             # si hay alguna std=0 ponla a 1\n",
    "    X=(X-X_media)/X_std             # normaliza\n",
    "    X=np.insert(X, 0, 1, axis=1)    # esta linea añade una columna de 1, feature engineering [1, f1, f2.., fn, f1f2...] (mejora un 10%)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se cargan los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos leidos...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones matriz de datos: (42000, 785)\n"
     ]
    }
   ],
   "source": [
    "datos=pd.read_csv('train.csv')        # imagenes de numeros\n",
    "print ('Datos leidos...')\n",
    "display(datos.head())\n",
    "matriz_datos=datos.values   \n",
    "print ('Dimensiones matriz de datos: {}'.format(matriz_datos.shape))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se visualiza una de las imagenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(matriz_datos[45,1:].reshape(28,28))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creacion de la matriz Y (variable dependiente, a predecir), (onehot)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de Y: (42000, 10)\n",
      "\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y=np.zeros((matriz_datos.shape[0],10))   \n",
    "print ('Dimension de Y: {}'.format(Y.shape))  \n",
    "print ('')\n",
    "for i in range(10):\n",
    "    Y[:,i]=np.where(matriz_datos[:,0]==i,1,0)\n",
    "print(Y[0:10,:]) # 10 primeras filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se separan las columnas etiqueta y se quitan las columnas que sean todo ceros.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension original de X: (42000, 784)\n",
      "\n",
      "Dimension limpia de X: (42000, 708)\n"
     ]
    }
   ],
   "source": [
    "etiquetas=matriz_datos[:,0]        # etiqueta, el numero en si, 42000 etiquetas\n",
    "X=matriz_datos[:,1:]               # datos numericos de los pixeles, cada columna es un pixel (variables indep)\n",
    "print ('Dimension original de X: {}'.format(X.shape)) \n",
    "print ('')\n",
    "X=X[:,X.sum(axis=0)!=0]            # se quitan las columnas=0 (la suma de los elementos es no nulo, no hay informacion)\n",
    "print ('Dimension limpia de X: {}'.format(X.shape))                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se dividen los datos en train y test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones train: X=(30000, 708), Y=(30000, 10)\n",
      "\n",
      "Dimensiones test: X=(12000, 708), Y=(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train=X[0:30000,:], Y[0:30000,:]        # datos de entranamiento\n",
    "X_train_sk=X_train.copy()                          # para sklearn\n",
    "\n",
    "X_test, Y_test=X[30000:,:], Y[30000:,:]            # datos de test\n",
    "X_test_sk=X_test.copy()                            # para sklearn\n",
    "\n",
    "print ('Dimensiones train: X={}, Y={}'.format(X_train.shape, Y_train.shape))  \n",
    "print ('')\n",
    "print ('Dimensiones test: X={}, Y={}'.format(X_test.shape, Y_test.shape)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etiquetas train y test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones etiquetas train: (30000,)\n",
      "\n",
      "Dimensiones etiquetas test: (12000,)\n"
     ]
    }
   ],
   "source": [
    "etiquetas_train=etiquetas[0:30000]       # etiquetas para entranamiento\n",
    "etiquetas_test=etiquetas[30000:]         # etiquetas para test\n",
    "\n",
    "print ('Dimensiones etiquetas train: {}'.format(etiquetas_train.shape))\n",
    "print ('')\n",
    "print ('Dimensiones etiquetas test: {}'.format(etiquetas_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normaliza los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-48062920a213>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"normalizador\" failed type inference due to: Internal error at <numba.typeinfer.CallConstraint object at 0x1365ea210>.\n",
      "\u001b[1m\u001b[1m\u001b[1m\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: resolving callee type: BoundFunction(array.mean for array(int64, 2d, A))\u001b[0m\n",
      "\u001b[0m\u001b[1m[2] During: typing of call at <ipython-input-5-48062920a213> (3)\n",
      "\u001b[0m\n",
      "Enable logging at debug level for details.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-48062920a213>\", line 3:\u001b[0m\n",
      "\u001b[1mdef normalizador(X):                # normalizador de X\n",
      "\u001b[1m    X_media=X.mean(axis=0)          # media de X\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit()\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"normalizador\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-48062920a213>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef normalizador(X):                # normalizador de X\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-48062920a213>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef normalizador(X):                # normalizador de X\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos normalizados.\n"
     ]
    }
   ],
   "source": [
    "X_train=normalizador(X_train)\n",
    "X_test=normalizador(X_test)\n",
    "print ('Datos normalizados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se buscan los parametros optimos para los 10 modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inicial=np.random.rand(X_train.shape[1]) # valores iniciales de los parametros alfa\n",
    "\n",
    "A_opt=np.zeros((X_train.shape[1],10))        # se crea la matriz para los parametros optimizados, alfas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Término de regularización L2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg=100.            # valor obtenido desde gridsearching  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizando 0 frente al resto.\n",
      "Optimizacion trust-constr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-8768f1891eb7>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"coste\" failed type inference due to: \u001b[1mUntyped global name 'f':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-8768f1891eb7>\", line 3:\u001b[0m\n",
      "\u001b[1mdef coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
      "\u001b[1m    return -(np.sum(np.log(f(X,a)))+np.dot((y-1).T,(np.dot(X,a))))/y.size+lambda_reg/(2.0*y.size)*np.dot(a[1:],a[1:])\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit()\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"coste\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-8768f1891eb7>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-8768f1891eb7>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "<ipython-input-4-8b898325e46c>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"grad_coste\" failed type inference due to: \u001b[1mUntyped global name 'f':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-8b898325e46c>\", line 3:\u001b[0m\n",
      "\u001b[1mdef grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
      "\u001b[1m    return (np.dot(X.T,(f(X,a)-y)))/y.size+lambda_reg/(2.0*y.size)*np.concatenate(([0], a[1:])).T\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit()\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"grad_coste\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-8b898325e46c>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-8b898325e46c>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 60, function evaluations: 60, CG iterations: 344, optimality: 7.93e-05, constraint violation: 0.00e+00, execution time:  2.2 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.53 segundos.\n",
      "\n",
      "\n",
      "Optimizando 1 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 52, function evaluations: 52, CG iterations: 281, optimality: 9.58e-05, constraint violation: 0.00e+00, execution time:  1.8 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 1.86 segundos.\n",
      "\n",
      "\n",
      "Optimizando 2 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 57, function evaluations: 57, CG iterations: 337, optimality: 9.64e-05, constraint violation: 0.00e+00, execution time:  2.0 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.06 segundos.\n",
      "\n",
      "\n",
      "Optimizando 3 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 56, function evaluations: 56, CG iterations: 308, optimality: 9.84e-05, constraint violation: 0.00e+00, execution time:  2.0 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.04 segundos.\n",
      "\n",
      "\n",
      "Optimizando 4 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 66, function evaluations: 66, CG iterations: 381, optimality: 9.08e-05, constraint violation: 0.00e+00, execution time:  2.3 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.37 segundos.\n",
      "\n",
      "\n",
      "Optimizando 5 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 56, function evaluations: 56, CG iterations: 319, optimality: 9.43e-05, constraint violation: 0.00e+00, execution time:  2.0 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.07 segundos.\n",
      "\n",
      "\n",
      "Optimizando 6 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 73, function evaluations: 73, CG iterations: 441, optimality: 8.64e-05, constraint violation: 0.00e+00, execution time:  2.7 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.69 segundos.\n",
      "\n",
      "\n",
      "Optimizando 7 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 58, function evaluations: 58, CG iterations: 289, optimality: 8.82e-05, constraint violation: 0.00e+00, execution time:  2.1 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.10 segundos.\n",
      "\n",
      "\n",
      "Optimizando 8 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 57, function evaluations: 57, CG iterations: 321, optimality: 7.92e-05, constraint violation: 0.00e+00, execution time:  2.1 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.14 segundos.\n",
      "\n",
      "\n",
      "Optimizando 9 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 67, function evaluations: 67, CG iterations: 438, optimality: 9.17e-05, constraint violation: 0.00e+00, execution time:  2.5 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.49 segundos.\n",
      "\n",
      "Tiempo total optimizacion custom: 22.37 segundos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inicio_opt=time.time()                       # inicio optimizacion\n",
    "for i in range(10):\n",
    "    print ('\\n\\nOptimizando {} frente al resto.'.format(i))\n",
    "\n",
    "    def opt_coste(a):                        # funcion a minimizar\n",
    "        return coste(X_train, a, Y_train[:,i], lambda_reg) \n",
    "\n",
    "    def opt_grad_coste(a):                   # gradiente \n",
    "        return grad_coste(X_train, a, Y_train[:,i], lambda_reg)\t\n",
    "\n",
    "    # metodo Nelder-Mead, Powell, CG, BFGS, Newton-CG, L-BFGS-B, TNC, COBYLA, SLSQP, trust-constr, \n",
    "    # dogleg, trust-ncg, trust-exact, trust-krylov (tambien custom)            \n",
    "    metodo='trust-constr'\n",
    "    print ('Optimizacion {}...'.format(metodo)) # minimizacion, optimizacion\n",
    "    i_opt=time.time() \n",
    "    modelo=minimize(opt_coste, val_inicial, method=metodo, jac=opt_grad_coste, tol=1e-4, options={'disp':True}) \n",
    "    print ('Hecho.')\n",
    "    print (\"Tiempo optimizacion: {:.2f} segundos.\" .format(time.time()-i_opt))  \n",
    "    A_opt[:,i]=modelo.x\n",
    "\n",
    "t_custom=time.time()-inicio_opt   # tiempo desde inicio hasta final minimizacion\n",
    "print ('\\nTiempo total optimizacion custom: {:.2f} segundos.\\n' .format(t_custom)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora se chequea el modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]                  # etiquetas predichas\n",
    "y_prob=[]                  # probabilidades de las etiquetas predichas\n",
    "\n",
    "def resumen(datos):        # testeo\n",
    "    for e in datos:\n",
    "        nombre, etiqueta, Xs=e         \n",
    "        etiq=etiqueta.size\n",
    "        probs=np.zeros((etiq,2))      # etiquetas con su probabilidad\n",
    "        cuenta=0                      # conteo de aciertos\n",
    "        for muestra in range(etiq): \n",
    "            for n in range(10):\n",
    "                alfa=A_opt[:,n]       # parametros de softmax\n",
    "                probs[n,0]=n\n",
    "                probs[n,1]=f(Xs[muestra,:],alfa)      # evaluacion de la prediccion\n",
    "                \n",
    "            probs=probs[probs[:,1].argsort()[::-1]]   # se pone la prob mas alta al principio\n",
    "            y_pred.append(probs[0,0])\n",
    "            y_prob.append(probs[0,1])\n",
    "            if probs[0,0]==etiqueta[muestra]:         # si se acierta +1\n",
    "                cuenta+=1\n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados train y test Custom.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento  :\n",
      "27950 correctos de 30000 ==> 93.17% correcto\n",
      "\n",
      "Test  :\n",
      "10974 correctos de 12000 ==> 91.45% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen([('Entranamiento  :', etiquetas_train, X_train)])\n",
    "resumen([('Test  :', etiquetas_test, X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se guarda el entrenamiento, los alfas, en un csv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones matriz de parametros=(709, 10)\n"
     ]
    }
   ],
   "source": [
    "print ('Dimensiones matriz de parametros={}'.format(A_opt.shape))\n",
    "df=pd.DataFrame(A_opt, columns=[i+1 for i in range(A_opt.shape[1])])  # se guardan los parametros softmax en csv\n",
    "#df.to_csv('alfas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versión SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total optimizacion sklearn: 4.01 segundos.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/data/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "ini_opt_sk=time.time()\n",
    "logreg=LogisticRegression(C=0.01, penalty='l2', tol=0.0001, max_iter=70,\n",
    "                          solver='lbfgs', multi_class='multinomial').fit(X_train_sk, etiquetas_train)\n",
    "t_sklearn=time.time()-ini_opt_sk\n",
    "print ('\\nTiempo total optimizacion sklearn: {:.2f} segundos.\\n' .format(t_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chequeo modelo sklearn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_sk(datos):\n",
    "    for e in datos:\n",
    "        nombre, etiqueta, Xs=e\n",
    "        etiq=etiqueta.size\n",
    "        \n",
    "        y_pred_sk=logreg.predict(Xs)\n",
    "        \n",
    "        cuenta=0\n",
    "        for muestra in range(etiq):\n",
    "            if y_pred_sk[muestra]==etiqueta[muestra]:         \n",
    "                cuenta+=1\n",
    "        \n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados train y test Custom.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento  :\n",
      "28108 correctos de 30000 ==> 93.69% correcto\n",
      "\n",
      "Test  :\n",
      "11014 correctos de 12000 ==> 91.78% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen_sk([('Entranamiento  :', etiquetas_train, X_train_sk)])\n",
    "resumen_sk([('Test  :', etiquetas_test, X_test_sk)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación entre modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En tiempo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkLearn es 5.59 veces más rapido.\n"
     ]
    }
   ],
   "source": [
    "print ('SkLearn es {:.2f} veces más rapido.'.format(t_custom/t_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diferencia absoluta entre ambos modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay una diferencia entre ambos modelos del 4.84%.\n"
     ]
    }
   ],
   "source": [
    "y_pred_sk=logreg.predict(X_test_sk)\n",
    "comp=[y_pred[30000:][i]==y_pred_sk[i] for i in range(len(y_pred[30000:]))]\n",
    "n_equal=len([e for e in comp if e==False])/len(y_pred_sk)\n",
    "\n",
    "print ('Hay una diferencia entre ambos modelos del {:.2f}%.'.format(n_equal*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acierto en train y test de ambos modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento Custom:\n",
      "27950 correctos de 30000 ==> 93.17% correcto\n",
      "\n",
      "Test Custom:\n",
      "10974 correctos de 12000 ==> 91.45% correcto\n",
      "\n",
      "\n",
      "Entranamiento SkLearn:\n",
      "28108 correctos de 30000 ==> 93.69% correcto\n",
      "\n",
      "Test SkLearn:\n",
      "11014 correctos de 12000 ==> 91.78% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen([('Entranamiento Custom:', etiquetas_train, X_train)])\n",
    "resumen([('Test Custom:', etiquetas_test, X_test)])\n",
    "print ('')\n",
    "resumen_sk([('Entranamiento SkLearn:', etiquetas_train, X_train_sk)])\n",
    "resumen_sk([('Test SkLearn:', etiquetas_test, X_test_sk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
