{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística   (SoftMax)\n",
    "\n",
    "\n",
    "**Con datos del MNIST, clasificación de números escritos a mano. (1vsALL)**\n",
    "\n",
    "\n",
    "![](imgs/sig_plot.png)\n",
    "\n",
    "\n",
    "# Versión Custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando...\n",
      "\n",
      "Modelo SoftMax (MLR) : Numeros\n"
     ]
    }
   ],
   "source": [
    "import time                                                 # para tiempo\n",
    "inicio=time.time()                                          # momento inicial\n",
    "print ('Comenzando...\\n')\n",
    "print ('Modelo SoftMax (MLR) : Numeros')    \n",
    "import pandas as pd                                         # dataframe\n",
    "import numpy as np                                          # numerical python, algebra lineal\n",
    "import matplotlib.pyplot as plt                             # plots, graficos\n",
    "import seaborn as sns                                       # plots\n",
    "from sklearn.metrics import confusion_matrix                # metricas, matriz de confusion\n",
    "from scipy.optimize import minimize                         # minimizar, opt\n",
    "from numba import jit                                       # compilacion y paralelizacion, velocidad\n",
    "import warnings                                             # avisos\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)  # elimino un warning por valores NaN en logaritmos o /0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se crean las funciones de las ecuaciones principales del modelo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/sigmoide.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(X,a):                                 # funcion logistica, sigmoide, funcion del modelo, con z=X*alfa, el producto escalar\n",
    "    return 1.0/(1.0+np.exp(-np.dot(X,a)))   # Boltzmann con pivote, alfa[i]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/coste.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
    "    return -(np.sum(np.log(f(X,a)))+np.dot((y-1).T,(np.dot(X,a))))/y.size+lambda_reg/(2.0*y.size)*np.dot(a[1:],a[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](imgs/grad_coste.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
    "    return (np.dot(X.T,(f(X,a)-y)))/y.size+lambda_reg/(2.0*y.size)*np.concatenate(([0], a[1:])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para normalizar los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit()\n",
    "def normalizador(X):                # normalizador de X\n",
    "    X_media=X.mean(axis=0)          # media de X\n",
    "    X_std=X.std(axis=0)             # desviacion estandar de X\n",
    "    X_std[X_std==0]=1.0             # si hay alguna std=0 ponla a 1\n",
    "    X=(X-X_media)/X_std             # normaliza\n",
    "    X=np.insert(X, 0, 1, axis=1)    # esta linea añade una columna de 1, feature engineering [1, f1, f2.., fn, f1f2...] (mejora un 10%)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se cargan los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos leidos...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones matriz de datos: (42000, 785)\n"
     ]
    }
   ],
   "source": [
    "datos=pd.read_csv('train.csv')        # imagenes de numeros\n",
    "print ('Datos leidos...')\n",
    "display(datos.head())\n",
    "matriz_datos=datos.values   \n",
    "print ('Dimensiones matriz de datos: {}'.format(matriz_datos.shape))          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se visualiza una de las imagenes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(matriz_datos[3,1:].reshape(28,28))  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creacion de la matriz Y (variable dependiente, a predecir), (onehot)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension de Y: (42000, 10)\n",
      "\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "Y=np.zeros((matriz_datos.shape[0],10))   \n",
    "print ('Dimension de Y: {}'.format(Y.shape))  \n",
    "print ('')\n",
    "for i in range(10):\n",
    "    Y[:,i]=np.where(matriz_datos[:,0]==i,1,0)\n",
    "print(Y[0:10,:]) # 10 primeras filas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se separan las columnas etiqueta y se quitan las columnas que sean todo ceros.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension original de X: (42000, 784)\n",
      "\n",
      "Dimension limpia de X: (42000, 708)\n"
     ]
    }
   ],
   "source": [
    "etiquetas=matriz_datos[:,0]        # etiqueta, el numero en si, 42000 etiquetas\n",
    "X=matriz_datos[:,1:]               # datos numericos de los pixeles, cada columna es un pixel (variables indep)\n",
    "print ('Dimension original de X: {}'.format(X.shape)) \n",
    "print ('')\n",
    "X=X[:,X.sum(axis=0)!=0]            # se quitan las columnas=0 (la suma de los elementos es no nulo, no hay informacion)\n",
    "print ('Dimension limpia de X: {}'.format(X.shape))                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se dividen los datos en train y test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones train: X=(30000, 708), Y=(30000, 10)\n",
      "\n",
      "Dimensiones test: X=(12000, 708), Y=(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train=X[0:30000,:], Y[0:30000,:]        # datos de entranamiento\n",
    "X_train_sk=X_train.copy()                          # para sklearn\n",
    "\n",
    "X_test, Y_test=X[30000:,:], Y[30000:,:]            # datos de test\n",
    "X_test_sk=X_test.copy()                            # para sklearn\n",
    "\n",
    "print ('Dimensiones train: X={}, Y={}'.format(X_train.shape, Y_train.shape))  \n",
    "print ('')\n",
    "print ('Dimensiones test: X={}, Y={}'.format(X_test.shape, Y_test.shape)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etiquetas train y test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones etiquetas train: (30000,)\n",
      "\n",
      "Dimensiones etiquetas test: (12000,)\n"
     ]
    }
   ],
   "source": [
    "etiquetas_train=etiquetas[0:30000]       # etiquetas para entranamiento\n",
    "etiquetas_test=etiquetas[30000:]         # etiquetas para test\n",
    "\n",
    "print ('Dimensiones etiquetas train: {}'.format(etiquetas_train.shape))\n",
    "print ('')\n",
    "print ('Dimensiones etiquetas test: {}'.format(etiquetas_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normaliza los datos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-48062920a213>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"normalizador\" failed type inference due to: Internal error at <numba.typeinfer.CallConstraint object at 0x1365ea210>.\n",
      "\u001b[1m\u001b[1m\u001b[1m\u001b[0m\n",
      "\u001b[0m\u001b[1m[1] During: resolving callee type: BoundFunction(array.mean for array(int64, 2d, A))\u001b[0m\n",
      "\u001b[0m\u001b[1m[2] During: typing of call at <ipython-input-5-48062920a213> (3)\n",
      "\u001b[0m\n",
      "Enable logging at debug level for details.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-48062920a213>\", line 3:\u001b[0m\n",
      "\u001b[1mdef normalizador(X):                # normalizador de X\n",
      "\u001b[1m    X_media=X.mean(axis=0)          # media de X\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  @jit()\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"normalizador\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-48062920a213>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef normalizador(X):                # normalizador de X\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-5-48062920a213>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef normalizador(X):                # normalizador de X\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos normalizados.\n"
     ]
    }
   ],
   "source": [
    "X_train=normalizador(X_train)\n",
    "X_test=normalizador(X_test)\n",
    "print ('Datos normalizados.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se buscan los parametros optimos para los 10 modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_inicial=np.random.rand(X_train.shape[1]) # valores iniciales de los parametros alfa\n",
    "\n",
    "A_opt=np.zeros((X_train.shape[1],10))        # se crea la matriz para los parametros optimizados, alfas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Término de regularización L2.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg=100.            # valor obtenido desde gridsearching  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Optimizando 0 frente al resto.\n",
      "Optimizacion trust-constr...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-8768f1891eb7>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"coste\" failed type inference due to: \u001b[1mUntyped global name 'f':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-8768f1891eb7>\", line 3:\u001b[0m\n",
      "\u001b[1mdef coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
      "\u001b[1m    return -(np.sum(np.log(f(X,a)))+np.dot((y-1).T,(np.dot(X,a))))/y.size+lambda_reg/(2.0*y.size)*np.dot(a[1:],a[1:])\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit()\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"coste\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-8768f1891eb7>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-3-8768f1891eb7>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef coste(X,a,y,lambda_reg):              # funcion coste, funcion a minimizar \n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "<ipython-input-4-8b898325e46c>:1: NumbaWarning: \u001b[1m\n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"grad_coste\" failed type inference due to: \u001b[1mUntyped global name 'f':\u001b[0m \u001b[1m\u001b[1mcannot determine Numba type of <class 'function'>\u001b[0m\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-8b898325e46c>\", line 3:\u001b[0m\n",
      "\u001b[1mdef grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
      "\u001b[1m    return (np.dot(X.T,(f(X,a)-y)))/y.size+lambda_reg/(2.0*y.size)*np.concatenate(([0], a[1:])).T\n",
      "\u001b[0m    \u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0m\n",
      "  @jit()\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:178: NumbaWarning: \u001b[1mFunction \"grad_coste\" was compiled in object mode without forceobj=True.\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-8b898325e46c>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  state.func_ir.loc))\n",
      "/Users/data/Library/Python/3.7/lib/python/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \u001b[1m\n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\u001b[1m\n",
      "File \"<ipython-input-4-8b898325e46c>\", line 2:\u001b[0m\n",
      "\u001b[1m@jit()\n",
      "\u001b[1mdef grad_coste(X,a,y,lambda_reg):          # gradiente de la funcion coste con regularizacion\n",
      "\u001b[0m\u001b[1m^\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 60, function evaluations: 60, CG iterations: 344, optimality: 7.93e-05, constraint violation: 0.00e+00, execution time:  2.2 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.53 segundos.\n",
      "\n",
      "\n",
      "Optimizando 1 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 52, function evaluations: 52, CG iterations: 281, optimality: 9.58e-05, constraint violation: 0.00e+00, execution time:  1.8 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 1.86 segundos.\n",
      "\n",
      "\n",
      "Optimizando 2 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 57, function evaluations: 57, CG iterations: 337, optimality: 9.64e-05, constraint violation: 0.00e+00, execution time:  2.0 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.06 segundos.\n",
      "\n",
      "\n",
      "Optimizando 3 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 56, function evaluations: 56, CG iterations: 308, optimality: 9.84e-05, constraint violation: 0.00e+00, execution time:  2.0 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.04 segundos.\n",
      "\n",
      "\n",
      "Optimizando 4 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 66, function evaluations: 66, CG iterations: 381, optimality: 9.08e-05, constraint violation: 0.00e+00, execution time:  2.3 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.37 segundos.\n",
      "\n",
      "\n",
      "Optimizando 5 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 56, function evaluations: 56, CG iterations: 319, optimality: 9.43e-05, constraint violation: 0.00e+00, execution time:  2.0 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.07 segundos.\n",
      "\n",
      "\n",
      "Optimizando 6 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 73, function evaluations: 73, CG iterations: 441, optimality: 8.64e-05, constraint violation: 0.00e+00, execution time:  2.7 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.69 segundos.\n",
      "\n",
      "\n",
      "Optimizando 7 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 58, function evaluations: 58, CG iterations: 289, optimality: 8.82e-05, constraint violation: 0.00e+00, execution time:  2.1 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.10 segundos.\n",
      "\n",
      "\n",
      "Optimizando 8 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 57, function evaluations: 57, CG iterations: 321, optimality: 7.92e-05, constraint violation: 0.00e+00, execution time:  2.1 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.14 segundos.\n",
      "\n",
      "\n",
      "Optimizando 9 frente al resto.\n",
      "Optimizacion trust-constr...\n",
      "`gtol` termination condition is satisfied.\n",
      "Number of iterations: 67, function evaluations: 67, CG iterations: 438, optimality: 9.17e-05, constraint violation: 0.00e+00, execution time:  2.5 s.\n",
      "Hecho.\n",
      "Tiempo optimizacion: 2.49 segundos.\n",
      "\n",
      "Tiempo total optimizacion custom: 22.37 segundos.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inicio_opt=time.time()                       # inicio optimizacion\n",
    "for i in range(10):\n",
    "    print ('\\n\\nOptimizando {} frente al resto.'.format(i))\n",
    "\n",
    "    def opt_coste(a):                        # funcion a minimizar\n",
    "        return coste(X_train, a, Y_train[:,i], lambda_reg) \n",
    "\n",
    "    def opt_grad_coste(a):                   # gradiente \n",
    "        return grad_coste(X_train, a, Y_train[:,i], lambda_reg)\t\n",
    "\n",
    "    # metodo Nelder-Mead, Powell, CG, BFGS, Newton-CG, L-BFGS-B, TNC, COBYLA, SLSQP, trust-constr, \n",
    "    # dogleg, trust-ncg, trust-exact, trust-krylov (tambien custom)            \n",
    "    metodo='trust-constr'\n",
    "    print ('Optimizacion {}...'.format(metodo)) # minimizacion, optimizacion\n",
    "    i_opt=time.time() \n",
    "    modelo=minimize(opt_coste, val_inicial, method=metodo, jac=opt_grad_coste, tol=1e-4, options={'disp':True}) \n",
    "    print ('Hecho.')\n",
    "    print (\"Tiempo optimizacion: {:.2f} segundos.\" .format(time.time()-i_opt))  \n",
    "    A_opt[:,i]=modelo.x\n",
    "\n",
    "t_custom=time.time()-inicio_opt   # tiempo desde inicio hasta final minimizacion\n",
    "print ('\\nTiempo total optimizacion custom: {:.2f} segundos.\\n' .format(t_custom)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ahora se chequea el modelo.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]                  # etiquetas predichas\n",
    "y_prob=[]                  # probabilidades de las etiquetas predichas\n",
    "\n",
    "def resumen(datos):        # testeo\n",
    "    for e in datos:\n",
    "        nombre, etiqueta, Xs=e         \n",
    "        etiq=etiqueta.size\n",
    "        probs=np.zeros((etiq,2))      # etiquetas con su probabilidad\n",
    "        cuenta=0                      # conteo de aciertos\n",
    "        for muestra in range(etiq): \n",
    "            for n in range(10):\n",
    "                alfa=A_opt[:,n]       # parametros de softmax\n",
    "                probs[n,0]=n\n",
    "                probs[n,1]=f(Xs[muestra,:],alfa)      # evaluacion de la prediccion\n",
    "                \n",
    "            probs=probs[probs[:,1].argsort()[::-1]]   # se pone la prob mas alta al principio\n",
    "            y_pred.append(probs[0,0])\n",
    "            y_prob.append(probs[0,1])\n",
    "            if probs[0,0]==etiqueta[muestra]:         # si se acierta +1\n",
    "                cuenta+=1\n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados train y test Custom.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento  :\n",
      "27950 correctos de 30000 ==> 93.17% correcto\n",
      "\n",
      "Test  :\n",
      "10974 correctos de 12000 ==> 91.45% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen([('Entranamiento  :', etiquetas_train, X_train)])\n",
    "resumen([('Test  :', etiquetas_test, X_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Se guarda el entrenamiento, los alfas, en un csv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones matriz de parametros=(709, 10)\n"
     ]
    }
   ],
   "source": [
    "print ('Dimensiones matriz de parametros={}'.format(A_opt.shape))\n",
    "df=pd.DataFrame(A_opt, columns=[i+1 for i in range(A_opt.shape[1])])  # se guardan los parametros softmax en csv\n",
    "#df.to_csv('alfas.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versión SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tiempo total optimizacion sklearn: 4.01 segundos.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/data/Library/Python/3.7/lib/python/site-packages/sklearn/linear_model/logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "ini_opt_sk=time.time()\n",
    "logreg=LogisticRegression(C=0.01, penalty='l2', tol=0.0001, max_iter=70,\n",
    "                          solver='lbfgs', multi_class='multinomial').fit(X_train_sk, etiquetas_train)\n",
    "t_sklearn=time.time()-ini_opt_sk\n",
    "print ('\\nTiempo total optimizacion sklearn: {:.2f} segundos.\\n' .format(t_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chequeo modelo sklearn.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resumen_sk(datos):\n",
    "    for e in datos:\n",
    "        nombre, etiqueta, Xs=e\n",
    "        etiq=etiqueta.size\n",
    "        \n",
    "        y_pred_sk=logreg.predict(Xs)\n",
    "        \n",
    "        cuenta=0\n",
    "        for muestra in range(etiq):\n",
    "            if y_pred_sk[muestra]==etiqueta[muestra]:         \n",
    "                cuenta+=1\n",
    "        \n",
    "        print (\"\\n{}\".format(nombre))\n",
    "        print (\"{} correctos de {} ==> {:.4}% correcto\".format(cuenta, etiq, cuenta/etiq*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultados train y test Custom.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento  :\n",
      "28108 correctos de 30000 ==> 93.69% correcto\n",
      "\n",
      "Test  :\n",
      "11014 correctos de 12000 ==> 91.78% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen_sk([('Entranamiento  :', etiquetas_train, X_train_sk)])\n",
    "resumen_sk([('Test  :', etiquetas_test, X_test_sk)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación entre modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**En tiempo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkLearn es 5.59 veces más rapido.\n"
     ]
    }
   ],
   "source": [
    "print ('SkLearn es {:.2f} veces más rapido.'.format(t_custom/t_sklearn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diferencia absoluta entre ambos modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay una diferencia entre ambos modelos del 4.84%.\n"
     ]
    }
   ],
   "source": [
    "y_pred_sk=logreg.predict(X_test_sk)\n",
    "comp=[y_pred[30000:][i]==y_pred_sk[i] for i in range(len(y_pred[30000:]))]\n",
    "n_equal=len([e for e in comp if e==False])/len(y_pred_sk)\n",
    "\n",
    "print ('Hay una diferencia entre ambos modelos del {:.2f}%.'.format(n_equal*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Acierto en train y test de ambos modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entranamiento Custom:\n",
      "27950 correctos de 30000 ==> 93.17% correcto\n",
      "\n",
      "Test Custom:\n",
      "10974 correctos de 12000 ==> 91.45% correcto\n",
      "\n",
      "\n",
      "Entranamiento SkLearn:\n",
      "28108 correctos de 30000 ==> 93.69% correcto\n",
      "\n",
      "Test SkLearn:\n",
      "11014 correctos de 12000 ==> 91.78% correcto\n"
     ]
    }
   ],
   "source": [
    "resumen([('Entranamiento Custom:', etiquetas_train, X_train)])\n",
    "resumen([('Test Custom:', etiquetas_test, X_test)])\n",
    "print ('')\n",
    "resumen_sk([('Entranamiento SkLearn:', etiquetas_train, X_train_sk)])\n",
    "resumen_sk([('Test SkLearn:', etiquetas_test, X_test_sk)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
