{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy , scipy, matplotlib.pyplot as plt, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Short-Time Fourier Transform\n",
    "\n",
    "Musical signals are highly non-stationary, i.e., their statistics change over time. It would be rather meaningless to compute a single Fourier transform over an entire 10-minute song.\n",
    "\n",
    "The short-time Fourier transform (STFT) (Wikipedia; FMP, p. 53) is obtained by computing the Fourier transform for successive frames in a signal.\n",
    "\n",
    "X(m,ω)=∑nx(n)w(n−m)exp(−jωn)\n",
    " \n",
    "As we increase  m , we slide the window function  w  to the right. For the resulting frame,  x(n)w(n−m) , we compute the Fourier transform. Therefore, the STFT  X  is a function of both time,  m , and frequency,  ω .\n",
    "\n",
    "Let's load a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, sr = librosa.load('mp3/Adele - Rolling in the Deep-rYEDA3JcQqw.mp3')\n",
    "ipd.Audio(x, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "librosa.stft computes a STFT. We provide it a frame size, i.e. the size of the FFT, and a hop length, i.e. the frame increment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 1024\n",
    "n_fft = 4096\n",
    "X = librosa.stft(x, n_fft=n_fft, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert the hop length and frame size to units of seconds:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(hop_length)/sr # units of seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(n_fft)/sr  # units of seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For real-valued signals, the Fourier transform is symmetric about the midpoint. Therefore, librosa.stft only retains one half of the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This STFT has 1025 frequency bins and 10075 frames in time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame(X)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['10075']=[i*0+0j for i in range(len(df))]\n",
    "df['4858']=[i*0+0j for i in range(len(df))]\n",
    "df['4859']=[i*0+0j for i in range(len(df))]\n",
    "df=df.append([0*i for i in range(3)], ignore_index = True)\n",
    "\n",
    "df=df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[[i for i in range(len(df.columns)-8)]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real=df.apply(lambda x: x.real)\n",
    "real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imag=df.apply(lambda x: x.imag)\n",
    "imag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectrogram\n",
    "\n",
    "In music processing, we often only care about the spectral magnitude and not the phase content.\n",
    "\n",
    "The spectrogram (Wikipedia; FMP, p. 29, 55) shows the the intensity of frequencies over time. A spectrogram is simply the squared magnitude of the STFT:\n",
    "\n",
    "S(m,ω)=|X(m,ω)|^2\n",
    " \n",
    "The human perception of sound intensity is logarithmic in nature. Therefore, we are often interested in the log amplitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = librosa.amplitude_to_db(abs(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display any type of spectrogram in librosa, use librosa.display.specshow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.specshow(S, sr=sr, hop_length=hop_length, x_axis='time', y_axis='linear')\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mel-spectrogram\n",
    "librosa has some outstanding spectral representations, including librosa.feature.melspectrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hop_length = 256\n",
    "S = librosa.feature.melspectrogram(x, sr=sr, n_fft=4096, hop_length=hop_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(librosa.core.istft(S), rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The human perception of sound intensity is logarithmic in nature. Therefore, like the STFT-based spectrogram, we are often interested in the log amplitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logS = librosa.power_to_db(abs(S))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(librosa.core.istft(logS), rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display any type of spectrogram in librosa, use librosa.display.specshow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.specshow(logS, sr=sr, hop_length=hop_length, x_axis='time', y_axis='mel')\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using y_axis=mel plots the y-axis on the mel scale which is similar to the  log(1+f)  function:\n",
    "\n",
    "m=2595log10(1+f/700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# librosa.cqt\n",
    "Unlike the Fourier transform, but similar to the mel scale, the constant-Q transform uses a logarithmically spaced frequency axis.\n",
    "\n",
    "To plot a constant-Q spectrogram, will use librosa.cqt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmin = librosa.midi_to_hz(36)\n",
    "C = librosa.cqt(x, sr=sr, fmin=fmin, n_bins=72)\n",
    "logC = librosa.amplitude_to_db(abs(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.specshow(logC, sr=sr, x_axis='time', y_axis='cqt_note', fmin=fmin, cmap='coolwarm')\n",
    "plt.colorbar(format='%+2.0f dB');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Istft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3=librosa.core.istft(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(mp3, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "input_img = Input(shape=(df.shape[0], df.shape[1], 1))  \n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='valid')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (2, 2), activation='relu', padding='valid')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation=None, padding='valid')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse') #loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(real.values.reshape(1, df.shape[0], df.shape[1], 1), \n",
    "                real.values.reshape(1, df.shape[0], df.shape[1], 1),\n",
    "                epochs=15,\n",
    "                batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_R = autoencoder.predict(real.values.reshape(1, real.shape[0], real.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_R_df=pd.DataFrame(mp3_R.reshape(mp3_R.shape[1], mp3_R.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(imag.values.reshape(1, df.shape[0], df.shape[1], 1), \n",
    "                imag.values.reshape(1, df.shape[0], df.shape[1], 1),\n",
    "                epochs=15,\n",
    "                batch_size=1)\n",
    "mp3_I = autoencoder.predict(imag.values.reshape(1, imag.shape[0], imag.shape[1], 1))\n",
    "mp3_I_df=pd.DataFrame(mp3_I.reshape(mp3_I.shape[1], mp3_I.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recons=mp3_R_df+mp3_I_df*1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons=librosa.core.istft(df_recons.values)\n",
    "ipd.Audio(recons, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.DataFrame(S)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['19432']=[i*0 for i in range(len(df2))]\n",
    "df2['19433']=[i*0 for i in range(len(df2))]\n",
    "df2['19434']=[i*0 for i in range(len(df2))]\n",
    "df2['19435']=[i*0 for i in range(len(df2))]\n",
    "df2['19436']=[i*0 for i in range(len(df2))]\n",
    "df2['19437']=[i*0 for i in range(len(df2))]\n",
    "df2['19438']=[i*0 for i in range(len(df2))]\n",
    "df2['19439']=[i*0 for i in range(len(df2))]\n",
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(df.values.reshape(1, df.shape[0], df.shape[1], 1), \n",
    "                df.values.reshape(1, df.shape[0], df.shape[1], 1),\n",
    "                epochs=15,\n",
    "                batch_size=10)\n",
    "mp3 = autoencoder.predict(df.values.reshape(1, df.shape[0], df.shape[1], 1))\n",
    "mp3_df=pd.DataFrame(mp3.reshape(mp3.shape[1], mp3.shape[2]))\n",
    "\n",
    "recons=librosa.core.istft(mp3_df.values)\n",
    "ipd.Audio(recons, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons=librosa.core.griffinlim(mp3_df.values, n_iter=100)\n",
    "ipd.Audio(recons, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(df2.shape[0], df2.shape[1], 1))  \n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (2, 2), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(64, (2, 2), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (2, 2), activation=None, padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='mse') #loss='binary_crossentropy')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(df2.values.reshape(1, df2.shape[0], df2.shape[1], 1), \n",
    "                df2.values.reshape(1, df2.shape[0], df2.shape[1], 1),\n",
    "                epochs=15,\n",
    "                batch_size=1)\n",
    "mp3 = autoencoder.predict(df2.values.reshape(1, df2.shape[0], df2.shape[1], 1))\n",
    "mp3_df=pd.DataFrame(mp3.reshape(mp3.shape[1], mp3.shape[2]))\n",
    "\n",
    "recons=librosa.core.griffinlim(librosa.db_to_power(mp3_df.values), n_iter=40)\n",
    "ipd.Audio(recons, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recons=librosa.core.griffinlim(mp3_df.values, n_iter=40)\n",
    "ipd.Audio(librosa.db_to_power(recons), rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
